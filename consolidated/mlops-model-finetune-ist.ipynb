{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bd4cbe6-a20b-457f-a019-aae403938c0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Orchestrate model evaluation with Amazon SageMaker Pipelines\n",
    "  \n",
    "The goal of this notebook is to provide an implementation of a multi-step SageMaker pipeline that will take care of multiple models evaluation, selection and registration into the SageMaker model registry.  \n",
    "For running this example we will use a model loaded from [Amazon Sagemaker Jumpstart SDK](https://aws.amazon.com/sagemaker/jumpstart/) models that will be finetuned and then evaluated.  \n",
    "This notebook is also using other Amazon SageMaker components:  \n",
    "\n",
    "[Amazon SageMaker Pipelines](https://aws.amazon.com/sagemaker/pipelines/) is a purpose-built workflow orchestration service to automate all phases of machine learning (ML) from data pre-processing to model monitoring. With an intuitive UI and Python SDK you can manage repeatable end-to-end ML pipelines at scale. The native integration with multiple AWS services allows you to customize the ML lifecycle based on your MLOps requirements.\n",
    "SageMaker Model Registry\n",
    "\n",
    "[Amazon SageMaker Model Registry](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html) is a purpose-built metadata store to manage the entire lifecycle of ML models from training to inference. Whether you prefer to store your model artifacts (model framework files, container image) in AWS (Amazon ECR) or outside of AWS in any third party Docker repository, you can now track them all in Amazon SageMaker Model Registry. You also have the flexibility to register a model without read/write permissions to the associated container image. If you want to track an ML model in a private repository, set the optional ‘SkipModelValidation’ parameter to ‘All’ at the time of registration. Later you can also deploy these models for inference in Amazon SageMaker.\n",
    "\n",
    "[Amazon SageMaker Clarify](https://aws.amazon.com/sagemaker/clarify/) provides purpose-built tools to gain greater insights into your ML models and data, based on metrics such as accuracy, robustness, toxicity, and bias to improve model quality and support responsible AI initiative. With the rise of generative AI, data scientists and ML engineers can leverage publicly available foundation models (FMs) to accelerate speed-to-market. To remove the heavy lifting of evaluating and selecting the right FM for your use case, Amazon SageMaker Clarify supports FM evaluation to help you quickly evaluate, compare, and select the best FM for your use case based on a variety of criteria across different tasks within minutes. It allows you to adopt FMs faster and with confidence.\n",
    "To perform evaluation we are using the open source library [FMEval](https://github.com/aws/fmeval) that empowers SageMaker Clarify FM model evaluation.\n",
    "\n",
    "This example is built by following the best practices explained in the blog post [Operationalize LLM Evaluation at Scale using Amazon SageMaker Clarify and MLOps services](https://aws.amazon.com/blogs/machine-learning/operationalize-llm-evaluation-at-scale-using-amazon-sagemaker-clarify-and-mlops-services/). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342165dc-1709-456a-ad8f-ec7a5a6e2c05",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Environment setup\n",
    "First we need to install required dependencies and import required libraries.  \n",
    "We also create a sagemaker SDK *config.yml* file with basic pipeline configuration.\n",
    "This file *config.yml* contains general pipeline parameters like the default pipeline container instance type and the path to the file *dependencies.txt* containing the required dependencies.\n",
    "These dependencies will be automatically downloaded from the pipeline container at the start of each pipeline step. We will create *requirements.txt* file later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971e8e6ca28a3752",
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install fmeval==0.4.0\n",
    "!pip3 install sagemaker==2.208"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76487ff0709f4921",
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.function_step import step\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.yaml\n",
    "SchemaVersion: '1.0'\n",
    "SageMaker:\n",
    "  PythonSDK:\n",
    "    Modules:\n",
    "      RemoteFunction:\n",
    "        # role arn is not required if in SageMaker Notebook instance or SageMaker Studio\n",
    "        # Uncomment the following line and replace with the right execution role if in a local IDE\n",
    "        InstanceType: ml.m5.xlarge\n",
    "        Dependencies: ./requirements.txt\n",
    "        IncludeLocalWorkDir: true\n",
    "        CustomFileFilter:\n",
    "          IgnoreNamePatterns: # files or directories to ignore\n",
    "          - \"*.ipynb\" # all notebook files\n",
    "          - \"__pycache__\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-04T12:11:10.366071Z",
     "start_time": "2024-07-04T12:11:10.225088Z"
    }
   },
   "id": "f28d9015ac8aa77d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.environ[\"SAGEMAKER_USER_CONFIG_OVERRIDE\"] = os.getcwd()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d328be880820d086"
  },
  {
   "cell_type": "markdown",
   "id": "4b4d5f58-65e2-4d01-8303-8a2d420e09bf",
   "metadata": {},
   "source": [
    "### Evaluation and Fine-Tuning dataset preparation - preprocess step\n",
    "*output_data_path* will contain the outputs artifacts of the pipeline.\n",
    "We then add **preprocess** as our first pipeline step. This step will take care of any data preprocessing that must be done to create the evaluation and fine-tuning dataset.\n",
    "In this example we are going to download the [SCIQ](https://huggingface.co/datasets/sciq) dataset and create from it a dataset for instruction fine-tuning. We also create the evaluation dataset.\n",
    "The output path of the datasets will be saved into *preprocess_step_ret* object.\n",
    "Keep in mind the *pipeline_name* as it will be used in SageMaker Studio to find our pipeline in the UI.\n",
    "Also keep in mind the path of the S3 bucket used as output for reviewing the output artifacts at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@step(name=\"preprocess\")\n",
    "def preprocess_ist(s3_output_path):\n",
    "    \n",
    "    from sagemaker.s3 import S3Uploader\n",
    "    from datasets import load_dataset\n",
    "    import json\n",
    "    import os\n",
    "    \n",
    "    def safe_open_w(path):\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        return open(path, 'w')\n",
    "\n",
    "    def write_to_file(input_str, file_path):\n",
    "        with safe_open_w(file_path) as text_file:\n",
    "            text_file.write(input_str)\n",
    "\n",
    "    dataset_path = 'allenai/sciq'\n",
    "    dataset = load_dataset(dataset_path)\n",
    "\n",
    "    dataset_training_df = dataset['train'].to_pandas()\n",
    "    dataset_training_df = dataset_training_df.sample(n=400, random_state=42, ignore_index=True)\n",
    "\n",
    "    finetuning_dataset_filename = \"dataset_finetune_ist.jsonl\"\n",
    "    template_filename = \"template.json\"\n",
    "    evaluation_dataset_filename = \"dataset_evaluation.jsonl\"\n",
    "    finetuning_dataset_local_path = f\"./output/{dataset_path}/{finetuning_dataset_filename}\"\n",
    "    evaluation_dataset_local_path = f\"./output/{dataset_path}/{evaluation_dataset_filename}\"\n",
    "    template_local_path = f\"./output/{dataset_path}/{template_filename}\"\n",
    "\n",
    "    # Write template file\n",
    "    template = {\n",
    "        \"prompt\": \"You are an expert answering science related question.\\n\\n### Answer this question:\\n{question}\\n\",\n",
    "        \"completion\": \"{correct_answer}\"\n",
    "    }\n",
    "    with safe_open_w(template_local_path) as text_file:\n",
    "        json.dump(template, text_file)\n",
    "\n",
    "    # Create IST dataset\n",
    "    dataset_train_ist_df = dataset_training_df[['question', 'correct_answer']].copy()\n",
    "    dataset_train_ist_df.to_json(finetuning_dataset_local_path, orient=\"records\", lines=True)\n",
    "\n",
    "    # Create evaluation dataset\n",
    "    dataset_evaluation_df = dataset_training_df[['question', 'correct_answer']].copy()\n",
    "    dataset_evaluation_df[\n",
    "        \"question\"] = \"You are an expert answering science related question.\\n\\n### Answer this question:\\n\" + \\\n",
    "                      dataset_evaluation_df[\"question\"].astype(str)\n",
    "    dataset_evaluation_df = dataset_evaluation_df.rename(\n",
    "        columns={\"correct_answer\": \"target_output\", \"question\": \"model_input\"})\n",
    "    dataset_evaluation_df.to_json(evaluation_dataset_local_path, orient=\"records\", lines=True)\n",
    "\n",
    "    finetuning_dataset_s3_path = f\"{s3_output_path}/{dataset_path}/finetuning/ist\"\n",
    "    evaluation_dataset_s3_path = f\"{s3_output_path}/{dataset_path}/evaluation\"\n",
    "\n",
    "    print(\"Uploading finetuning dataset...\")\n",
    "    S3Uploader.upload(finetuning_dataset_local_path, f\"{finetuning_dataset_s3_path}\")\n",
    "    print(\"Uploading template...\")\n",
    "    S3Uploader.upload(template_local_path, f\"{finetuning_dataset_s3_path}\")\n",
    "    print(\"Uploading evaluation dataset...\")\n",
    "    S3Uploader.upload(evaluation_dataset_local_path, f\"{evaluation_dataset_s3_path}\")\n",
    "\n",
    "    return {\"s3_output_path\": s3_output_path,\n",
    "            \"s3_finetune_dataset_path\": finetuning_dataset_s3_path,\n",
    "            \"s3_evaluation_data_location\": f\"{evaluation_dataset_s3_path}/{evaluation_dataset_filename}\"}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "638ea27c78ce17c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4538466bfbdc3e26",
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_name = \"mlops-model-finetune-dft\"\n",
    "\n",
    "default_bucket = sagemaker.Session().default_bucket()\n",
    "output_data_path = (\"s3://\"+ default_bucket + \"/pipelines_examples/\" + pipeline_name)\n",
    "\n",
    "# You can add your own evaluation dataset code into this step\n",
    "preprocess_step_ret = preprocess_ist(output_data_path)\n",
    "\n",
    "print(\"The pipeline name is \"+pipeline_name)\n",
    "# Mark the name of this bucket for reviewing the artifacts generated by this pipeline at the end of the execution\n",
    "print(\"Output S3 bucket: \"+output_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5425f135245e0944",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Setup the model from SageMaker Jumpstart to be finetuned with am instruction dataset\n",
    "Setup the model_id from SageMaker Jumpstart that we are going to finetune with an instruction dataset. We will use the default Jumpstart training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca692e551ee74f31",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We setup required model parameters\n",
    "model = {\n",
    "    \"model_id\": \"meta-textgeneration-llama-2-7b\"\n",
    "}\n",
    "model[\"model_name\"] = model[\"model_id\"]+\"_ist\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18801dd08ba069f7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We are now going to create the pipeline steps. We start with a **finetune** step followed by a **deploy** and **evaluation** steps.\n",
    "The result of evaluation will be saved into *evaluate_finetuned_model_ret* object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@step(name=\"finetune_\"+model[\"model_name\"])\n",
    "def jumpstart_finetune(model, preprocess_step_ret):\n",
    "    \n",
    "    from sagemaker.jumpstart.estimator import JumpStartEstimator\n",
    "\n",
    "    model_id = model[\"model_id\"]\n",
    "\n",
    "    train_data_path = preprocess_step_ret[\"s3_finetune_dataset_path\"]\n",
    "\n",
    "    estimator = JumpStartEstimator(\n",
    "        model_id=model_id,\n",
    "        environment={\"accept_eula\": \"true\"},\n",
    "        disable_output_compression=False)\n",
    "\n",
    "    estimator.fit(inputs={\"training\": train_data_path})\n",
    "    training_job_name = estimator.latest_training_job.name\n",
    "\n",
    "    return {\"training_job_name\": training_job_name}\n",
    "\n",
    "\n",
    "@step(name=\"deploy_\"+model[\"model_name\"])\n",
    "def jumpstart_deploy(model, finetune_step_ret=None):\n",
    "    \n",
    "    import sagemaker\n",
    "    from sagemaker.jumpstart.model import JumpStartModel\n",
    "    from sagemaker.jumpstart.estimator import JumpStartEstimator\n",
    "\n",
    "    model_id = model[\"model_id\"]\n",
    "\n",
    "    if finetune_step_ret is None:\n",
    "        model = JumpStartModel(model_id=model_id)\n",
    "        predictor = model.deploy(accept_eula=True)\n",
    "        return {\"model_endpoint\": predictor.endpoint_name, \"model_deployed\": True, \"is_finetuned_model\": False}\n",
    "    \n",
    "    else:\n",
    "        training_job_name = finetune_step_ret[\"training_job_name\"]\n",
    "\n",
    "        estimator = JumpStartEstimator.attach(training_job_name, model_id=model_id)\n",
    "        estimator.logs()\n",
    "        predictor = estimator.deploy(serializer=sagemaker.serializers.JSONSerializer(),\n",
    "                                     deserializer=sagemaker.deserializers.JSONDeserializer())\n",
    "\n",
    "        return {\"model_endpoint\": predictor.endpoint_name, \"model_deployed\": True, \"is_finetuned_model\": True, \"training_job_name\": training_job_name}\n",
    "\n",
    "    \n",
    "@step(name=\"evaluate_\"+model[\"model_name\"])\n",
    "def evaluation(model, preprocess_step_ret, deploy_step_ret):\n",
    "    \n",
    "    import boto3\n",
    "    import markdown\n",
    "    from sagemaker.s3_utils import parse_s3_url\n",
    "    from fmeval.data_loaders.data_config import DataConfig\n",
    "    from fmeval.reporting.eval_output_cells import EvalOutputCell\n",
    "    from fmeval.constants import MIME_TYPE_JSONLINES\n",
    "    from fmeval.model_runners.sm_jumpstart_model_runner import JumpStartModelRunner\n",
    "    from fmeval.eval_algorithms.factual_knowledge import FactualKnowledge, FactualKnowledgeConfig\n",
    "\n",
    "    s3 = boto3.client(\"s3\")\n",
    "\n",
    "    model_id = model[\"model_id\"]\n",
    "    model_name = model[\"model_name\"]\n",
    "    \n",
    "    # FMEval library needs three components:\n",
    "    # - The evaluation dataset\n",
    "    # - A model runner\n",
    "    # - An algorithm to use\n",
    "    # We will configure each of this components in the following lines:\n",
    "\n",
    "    # Get the dataset\n",
    "    data_s3_path = preprocess_step_ret[\"s3_evaluation_data_location\"]\n",
    "    bucket, object_key = parse_s3_url(data_s3_path)\n",
    "    print(bucket)\n",
    "    print(object_key)\n",
    "    s3.download_file(bucket, object_key, \"dataset.jsonl\")\n",
    "\n",
    "    # Configure FMEval for reading the dataset\n",
    "    config = DataConfig(\n",
    "        dataset_name=\"dataset\",\n",
    "        dataset_uri=\"dataset.jsonl\",\n",
    "        dataset_mime_type=MIME_TYPE_JSONLINES,\n",
    "        model_input_location=\"model_input\",\n",
    "        target_output_location=\"target_output\",\n",
    "    )\n",
    "\n",
    "    # Create a JumpStartModelRunner that will be used by FMEval library to perform the call to the model \n",
    "    # and the evaluation of each entry of the evaluation dataset\n",
    "    endpoint_name = deploy_step_ret[\"model_endpoint\"]\n",
    "    js_model_runner = JumpStartModelRunner(\n",
    "        endpoint_name=endpoint_name,\n",
    "        model_id=model_id,\n",
    "        custom_attributes=\"accept_eula=true\"\n",
    "    )\n",
    "\n",
    "    # Configure and launch FactualKnowledge evaluation algorithm\n",
    "    eval_output_all = []\n",
    "    eval_algo = FactualKnowledge(FactualKnowledgeConfig(\"<OR>\"))\n",
    "    eval_output = eval_algo.evaluate(\n",
    "        model=js_model_runner,\n",
    "        dataset_config=config,\n",
    "        prompt_template=\"$feature\",\n",
    "        save=True,\n",
    "    )\n",
    "    eval_output_all.append(eval_output)\n",
    "\n",
    "    # Save results to S3\n",
    "    s3 = boto3.resource(\"s3\")\n",
    "    output_bucket, output_index = parse_s3_url(preprocess_step_ret[\"s3_output_path\"])\n",
    "    \n",
    "    html = markdown.markdown(str(EvalOutputCell(eval_output[0])))\n",
    "    file_index = (\n",
    "            output_index\n",
    "            + \"/\"\n",
    "            + model_name\n",
    "            + \"_\"\n",
    "            + eval_algo.eval_name\n",
    "            + \".html\"\n",
    "    )\n",
    "\n",
    "    s3_object = s3.Object(bucket_name=output_bucket, key=file_index)\n",
    "    s3_object.put(Body=html)\n",
    "\n",
    "    return {\"evaluation_output\": eval_output_all, \"model_name\": model_name, \"model_id\":  model_id}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27b3770733cda8e8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336a4b0cf9ab3f0f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finetune_ret = jumpstart_finetune(model, preprocess_step_ret)\n",
    "\n",
    "# Deploy step is using the output from the finetune step (the training job name)\n",
    "deploy_ret = jumpstart_deploy(model, finetune_ret)\n",
    "\n",
    "# Evaluation step is using the output from preprocess (the S3 location of the evaluation dataset file) \n",
    "# and the output of the deploy step (the endpoint name)\n",
    "evaluate_ret = evaluation(model, preprocess_step_ret, deploy_ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f23d56614aea50",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Register the model in SageMaker Model Registry\n",
    "Now it's time to register the fine-tuned model into SageMaker Model Registry.\n",
    "WE implement all the required code in the **register** step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@step(name=\"register_model\")\n",
    "def register(evaluate_ret, deploy_ret, output_data_path, model_package_group_name, model_package_group_description):\n",
    "    \n",
    "    from sagemaker import ModelMetrics, MetricsSource\n",
    "    from sagemaker.jumpstart.model import JumpStartModel\n",
    "    from sagemaker.jumpstart.estimator import JumpStartEstimator\n",
    "    from sagemaker.s3_utils import parse_s3_url\n",
    "    import boto3\n",
    "    import json\n",
    "\n",
    "    sm_client = boto3.client(\"sagemaker\")\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "    eval_result = evaluate_ret[\"evaluation_output\"][0][0]\n",
    "\n",
    "     # Upload evaluation report of the best model to s3\n",
    "    eval_report_s3_uri = output_data_path + \"/evaluation-report/\" + evaluate_ret[\"model_name\"] + \".json\"\n",
    "    bucket, object_key = parse_s3_url(eval_report_s3_uri)\n",
    "    eval_report_str = json.dumps(\n",
    "    {\n",
    "        \"score\": eval_result.dataset_scores[0].value,\n",
    "        \"algorithm\": eval_result.dataset_scores[0].name,\n",
    "    })\n",
    "    \n",
    "    s3_client.put_object(Body=eval_report_str, Bucket=bucket, Key=object_key)\n",
    "\n",
    "    # Create model_metrics as per evaluation report in s3\n",
    "    model_metrics = ModelMetrics(\n",
    "        model_statistics=MetricsSource(\n",
    "            s3_uri=eval_report_s3_uri,\n",
    "            content_type=\"application/json\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        sm_client.describe_model_package_group(\n",
    "            ModelPackageGroupName=model_package_group_name\n",
    "        )\n",
    "    except:\n",
    "        model_package_group_input_dict = {\n",
    "            \"ModelPackageGroupName\": model_package_group_name,\n",
    "            \"ModelPackageGroupDescription\": model_package_group_description,\n",
    "        }\n",
    "        create_model_package_group_response = sm_client.create_model_package_group(\n",
    "            **model_package_group_input_dict\n",
    "        )\n",
    "        print(\n",
    "            \"ModelPackageGroup Arn : {}\".format(\n",
    "                create_model_package_group_response[\"ModelPackageGroupArn\"]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    # Register Model\n",
    "    model_id = evaluate_ret[\"model_id\"]\n",
    "\n",
    "    if deploy_ret[\"is_finetuned_model\"] is True:\n",
    "        training_job_name = deploy_ret[\"training_job_name\"]\n",
    "\n",
    "        estimator = JumpStartEstimator.attach(training_job_name, model_id=model_id)\n",
    "        model_package = estimator.register(\n",
    "            model_package_group_name=model_package_group_name,\n",
    "            content_types=[\"application/json\"],\n",
    "            response_types=[\"application/json\"],\n",
    "            customer_metadata_properties={\n",
    "                \"score\": str(eval_result.dataset_scores[0].value),\n",
    "                \"algorithm\": eval_result.dataset_scores[0].name,\n",
    "            },\n",
    "            model_metrics=model_metrics,\n",
    "        )\n",
    "    else:\n",
    "        js_model = JumpStartModel(model_id=model_id)\n",
    "\n",
    "        if isinstance(js_model.model_data, dict) and 'S3DataSource' in js_model.model_data:\n",
    "            js_model.model_data = js_model.model_data['S3DataSource']['S3Uri']\n",
    "\n",
    "        model_package = js_model.register(\n",
    "            model_package_group_name=model_package_group_name,\n",
    "            image_uri=js_model.image_uri,\n",
    "            content_types=[\"application/json\"],\n",
    "            response_types=[\"application/json\"],\n",
    "            customer_metadata_properties={\n",
    "                \"score\": str(eval_result.dataset_scores[0].value),\n",
    "                \"algorithm\": eval_result.dataset_scores[0].name,\n",
    "            },\n",
    "            skip_model_validation=\"All\",\n",
    "            model_metrics=model_metrics,\n",
    "        )\n",
    "\n",
    "    model_package_arn = model_package.model_package_arn\n",
    "\n",
    "    return {\"model_package_arn\", model_package_arn}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d5c2bdff24a569b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set a package group name and description\n",
    "model_package_group_name = \"MlOpsModelFinetuneIst\"\n",
    "model_package_group_description = \"MLOps Model Finetune Ist\"\n",
    "\n",
    "# We will register the best model in the model register. The best model name is contained in the return object of the selection step\n",
    "register_ret = register(evaluate_ret,\n",
    "                        deploy_ret,\n",
    "                        output_data_path,\n",
    "                        model_package_group_name,\n",
    "                        model_package_group_description)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b05c18a5295ce0a"
  },
  {
   "cell_type": "markdown",
   "id": "478f53e262aafb7c",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "The last pipeline step is dedicated to cleanup all the resource that we are going to instantiate with the pipeline inside a **cleanup** step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@step(name=\"cleanup_\"+model[\"model_name\"])\n",
    "def cleanup(register_ret, *deploy_rets):\n",
    "    import boto3\n",
    "\n",
    "    for deploy_ret in deploy_rets:\n",
    "        client = boto3.client('sagemaker')\n",
    "        client.delete_endpoint(EndpointName=deploy_ret[\"model_endpoint\"])\n",
    "        client.delete_endpoint_config(EndpointConfigName=deploy_ret[\"model_endpoint\"])\n",
    "\n",
    "    return {\"cleanup_done\": True}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2c6ed7255439a21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71735d24ab99ad89",
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We append register_ret to make cleanup step dependent on register step\n",
    "cleanup_ret = cleanup(register_ret, deploy_ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce0babb-70c2-4b2b-bde8-f0986109fde6",
   "metadata": {},
   "source": [
    "### Creating and launching the pipeline\n",
    "We are finally ready to create and launch the pipeline but before doing that we will need to create a requirements.txt file.\n",
    "As a best practice we are reading the current sagemaker library version that we are using to create the pipeline and set it as a requirement into the requirement file.\n",
    "Keeping the same sagemaker version in the creation and running phase will allow us to avoid any deserialization issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c682ddc-f4fc-4ef4-8081-d753032f2888",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(\"requirements.txt\"):\n",
    "    os.remove(\"requirements.txt\")\n",
    "\n",
    "with open('requirements.txt', 'w') as req_file:\n",
    "    req_file.write(\"fmeval==0.4.0\\n\")\n",
    "    req_file.write(\"sagemaker==\" + str(sagemaker.__version__) + \"\\n\")\n",
    "    req_file.write(\"datasets\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b5abfcc508e191",
   "metadata": {},
   "source": [
    "In the last cell of this notebook we are creating the pipeline and serializing it to S3. \n",
    "Don't forget to attach the execution role with sufficient permission and the return results from the last steps of our pipeline.\n",
    "We are now ready to start the pipeline execution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f091649f823362",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "\n",
    "pipeline = Pipeline(name=pipeline_name, steps=[cleanup_ret])\n",
    "pipeline.upsert(role)\n",
    "pipeline.start()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
